{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# install the requirements\n",
    "# pip install torch torchvision\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Modelos de Lenguaje de OpenAI\n",
    "\n",
    "A mitad de febrero, [OpenAI publicó un modelo de lenguaje](https://blog.openai.com/better-language-models/) capaz de generar lenguaje natural de formar coherente. Este modelo es generalista y, a pesar de ello, es capaz de rivalizar con los mejores sistemas específicos en tareas como comprensión automática de lenguaje natural, traducción automática, búsqueda de respuestas y resumen automático.\n",
    "\n",
    "Este modelo, llamado GPT-2, es el resultado de haber entrenado con 8 millones de páginas web (40 GB) con 1 500 millones de parámetros con un único objetivo: predecir cuál es la siguiente palabra.\n",
    "\n",
    "Sin embargo, OpenAI no ha publicado el modelo para evitar que alguien con malas intenciones pueda hacer un uso dañino de esta tecnología. Sí que han publicado una versión simplificada y más pequeña, y el paper [\"Language Models are Unsupervised Multitask Learners\"](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), en el que explican todo el proceso.\n",
    "\n",
    "Con ganas y GPUs suficientes (+ tiempo y dinero), se puede replicar el proceso. Otras lecturas interesantes, sobre el tema: \n",
    "\n",
    "- [OpenAI's new Multitalented AI Writes, Translates, and Slanders](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2)\n",
    "- [Some thoughts on zero-day threats in AI, and OpenAI's GP2](https://www.fast.ai/2019/02/15/openai-gp2/)\n",
    "\n",
    "\n",
    "Este código de ejemplo está inspirado en [un tweet de Thomas Wolf](https://twitter.com/Thom_Wolf/status/1097465312579072000), de [Hugging Face](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación, definimos una función para:\n",
    "\n",
    "1. tokenizar el texto de entrada y codificarlo como un vector con los pesos obtenidos por el modelo GPT2\n",
    "2. predecir la siguiente palabra más frecuente\n",
    "3. decodificar el vector como una secuencia de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def generate(text, length=50):\n",
    "    \"\"\"Generate automatic Natural Language from the input text\"\"\"\n",
    "    vec_text = tokenizer.encode(text)\n",
    "    my_input, past = torch.tensor([vec_text]), None\n",
    "\n",
    "    for _ in range(length):\n",
    "        logits, past = model(my_input, past_key_values=past)\n",
    "        my_input = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "        vec_text.append(my_input.item())\n",
    "\n",
    "    return tokenizer.decode(vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only thing we can do to fight climate change is to introduce sensible laws, one of which is fossil fuel pollution control.\"\n",
      "\n",
      "Tennessee has attempted limited action by reaching a $50 million settlement and doing so with sponsorship from \n",
      "\n",
      "The only thing we can do to fight climate change is fight the rationalizations for global economic actions.\" Freeman added. \"Globalization's greed and empathy for the poor or minorities is one of its greatest threats.\"\n",
      "\n",
      "Read more \n",
      "\n",
      "The only thing we can do to fight climate change is to withdraw from it,\" Steven Thewlis, director of the World Wildlife Fund, said on CNN's \"State of the Union.\"\n",
      "\n",
      "The plan to withdraw from the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defino un texto de entrada\n",
    "text = \"The only thing we can do to fight climate change is\"\n",
    "\n",
    "# y generamos automáticamente las secuencias más probables\n",
    "for _ in range(3):\n",
    "    print(generate(text, 35), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A ti lo que te ocurre es que á se attar nos nec trétaisà cuando. Pour self étude j \n",
      "\n",
      "A ti lo que te ocurre es que parece batas kindnesses ocurres pire cientías, talaga nem \n",
      "\n",
      "A ti lo que te ocurre es que nen deimanciona a ellos sinimade habolá tan que como un \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defino un texto de entrada\n",
    "text = \"A ti lo que te ocurre es que\"\n",
    "\n",
    "# y generamos automáticamente las secuencias más probables\n",
    "for _ in range(3):\n",
    "    print(generate(text, 20), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was born in Spain so my mother language is Portuguese\n",
      "I was born in France so my mother language is English\n",
      "I was born in Italy so my mother language is Italian\n",
      "I was born in Greece so my mother language is English\n",
      "I was born in Russia so my mother language is english\n",
      "I was born in China so my mother language is not\n",
      "I was born in Japan so my mother language is slowly\n",
      "I was born in India so my mother language is Persian\n"
     ]
    }
   ],
   "source": [
    "countries = \"Spain France Italy Greece Russia China Japan India\".split()\n",
    "\n",
    "for country in countries:\n",
    "    text = f\"I was born in {country} so my mother language is\"\n",
    "    print(generate(text, 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# install the requirements\n",
    "# pip install torch torchvision\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Modelos de Lenguaje de OpenAI\n",
    "\n",
    "A mitad de febrero, [OpenAI publicó un modelo de lenguaje](https://blog.openai.com/better-language-models/) capaz de generar lenguaje natural de formar coherente. Este modelo es generalista y, a pesar de ello, es capaz de rivalizar con los mejores sistemas específicos en tareas como comprensión automática de lenguaje natural, traducción automática, búsqueda de respuestas y resumen automático.\n",
    "\n",
    "Este modelo, llamado GPT-2, es el resultado de haber entrenado con 8 millones de páginas web (40 GB) con 1 500 millones de parámetros con un único objetivo: predecir cuál es la siguiente palabra.\n",
    "\n",
    "Sin embargo, OpenAI no ha publicado el modelo para evitar que alguien con malas intenciones pueda hacer un uso dañino de esta tecnología. Sí que han publicado una versión simplificada y más pequeña, y el paper [\"Language Models are Unsupervised Multitask Learners\"](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), en el que explican todo el proceso.\n",
    "\n",
    "Con ganas y GPUs suficientes (+ tiempo y dinero), se puede replicar el proceso. Otras lecturas interesantes, sobre el tema: \n",
    "\n",
    "- [OpenAI's new Multitalented AI Writes, Translates, and Slanders](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2)\n",
    "- [Some thoughts on zero-day threats in AI, and OpenAI's GP2](https://www.fast.ai/2019/02/15/openai-gp2/)\n",
    "\n",
    "\n",
    "Este código de ejemplo está inspirado en [un tweet de Thomas Wolf](https://twitter.com/Thom_Wolf/status/1097465312579072000), de [Hugging Face](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A continuación, definimos una función para:\n",
    "\n",
    "1. tokenizar el texto de entrada y codificarlo como un vector con los pesos obtenidos por el modelo GPT2\n",
    "2. predecir la siguiente palabra más frecuente\n",
    "3. decodificar el vector como una secuencia de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def generate(text, length=50):\n",
    "    \"\"\"Generate automatic Natural Language from the input text\"\"\"\n",
    "    vec_text = tokenizer.encode(text)\n",
    "    my_input, past = torch.tensor([vec_text]), None\n",
    "\n",
    "    for _ in range(length):\n",
    "        logits, past = model(my_input, past_key_values=past)\n",
    "        my_input = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "        vec_text.append(my_input.item())\n",
    "\n",
    "    return tokenizer.decode(vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only think we can do to fight climate change is stem the source of the bunsen system,\" said Kanaana Read, office manager for the Farm Animal Confidence Association.\n",
      "\n",
      "Watch Grant Britain's Open Road announcement including \n",
      "\n",
      "--------------------------------------------------\n",
      "The only think we can do to fight climate change is to help Canadian farmers,\" Gunden said. \"On the other hand, some of the smaller farmers have opened up new locations and some GMO crops are being introduced in the \n",
      "\n",
      "--------------------------------------------------\n",
      "The only think we can do to fight climate change is say NO else, and build a platform and great response to it,\" he quipped. \"And you'll be in a better position now to criticize immigrants and immigrants groups that \n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# defino un texto de entrada\n",
    "text = \"The only think we can do to fight climate change is\"\n",
    "\n",
    "# y generamos automáticamente las secuencias más probables\n",
    "for _ in range(3):\n",
    "    print(generate(text, 35), \"\\n\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since I was born in Spain my mother language is Spanish\n",
      "Since I was born in France my mother language is French\n",
      "Since I was born in Italy my mother language is Italian\n",
      "Since I was born in Greece my mother language is som\n",
      "Since I was born in Russia my mother language is Russian\n",
      "Since I was born in China my mother language is lit\n",
      "Since I was born in Japan my mother language is j\n",
      "Since I was born in India my mother language is Hindi\n"
     ]
    }
   ],
   "source": [
    "countries = \"Spain France Italy Greece Russia China Japan India\".split()\n",
    "\n",
    "for country in countries:\n",
    "    text = f\"Since I was born in {country} my mother language is\"\n",
    "    print(generate(text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm thirsty and I need to drink a glass of water\n",
      "I'm thirsty and I need to drink a glass of wine\n",
      "I'm thirsty and I need to drink a glass of water\n",
      "I'm thirsty and I need to drink a glass of wine\n",
      "I'm thirsty and I need to drink a glass of water\n",
      "I'm thirsty and I need to drink a glass of wine\n",
      "I'm thirsty and I need to drink a glass of water\n",
      "I'm thirsty and I need to drink a glass of water\n",
      "I'm thirsty and I need to drink a glass of water\n",
      "I'm thirsty and I need to drink a glass of water\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    text = \"I'm thirsty and I need to drink a glass of\"\n",
    "    print(generate(text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 10 years practicing kung-fu I'm a bit heavy-\n",
      "After 10 years practicing kung-fu I'm a more experienced force\n",
      "After 10 years practicing kung-fu I'm a big fan of\n",
      "After 10 years practicing kung-fu I'm a full-time\n",
      "After 10 years practicing kung-fu I'm a bit old,\n",
      "After 10 years practicing kung-fu I'm a big fan.\n",
      "After 10 years practicing kung-fu I'm a number two in\n",
      "After 10 years practicing kung-fu I'm a big believer in\n",
      "After 10 years practicing kung-fu I'm a total novice,\n",
      "After 10 years practicing kung-fu I'm a master of this\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    text = \"After 10 years practicing kung-fu I'm a\"\n",
    "    print(generate(text, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To become a good person, you need to change your mindset, or\n",
      "To become a good person, you need to be someone of integrity who\n",
      "To become a good person, you need to learn the things that're\n",
      "To become a good person, you need to know the big stories and\n",
      "To become a good person, you need to be deaf. If you\n",
      "To become a good person, you need to know how to live your\n",
      "To become a good person, you need to have self-writing.\n",
      "To become a good person, you need to go through a little bit\n",
      "To become a good person, you need to have an idea of what\n",
      "To become a good person, you need to do everything within your power\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    text = \"To become a good person, you need to\"\n",
    "    print(generate(text, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
